# Steam Bundle Scraper

Sistema completo de scraping de bundles da Steam com detec√ß√£o de promo√ß√µes falsas e sincroniza√ß√£o cloud.

## üéØ Caracter√≠sticas

- **Scraping H√≠brido**: aiohttp (r√°pido) + Playwright (pre√ßos din√¢micos)
- **Banco de Dados**: PostgreSQL com hist√≥rico completo de pre√ßos
- **Detec√ß√£o de Fraudes**: Identifica "metade do dobro" automaticamente
- **Prote√ß√£o SD Card**: Otimizado para Orange Pi (logs em RAM)
- **Sync Cloud**: Sincroniza√ß√£o autom√°tica com Supabase
- **Cron Robusto**: Execu√ß√µes peri√≥dicas sem memory leaks

## üìÅ Estrutura do Projeto

```
SteamBundleAPI/
‚îú‚îÄ‚îÄ scraper/                    # M√≥dulo principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py             # Scraping com aiohttp
‚îÇ   ‚îú‚îÄ‚îÄ browser_scraper.py     # Scraping com Playwright
‚îÇ   ‚îú‚îÄ‚îÄ mapper.py              # HTML ‚Üí Objetos
‚îÇ   ‚îú‚îÄ‚îÄ filters.py             # Valida√ß√µes e filtros
‚îÇ   ‚îú‚îÄ‚îÄ database.py            # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ sync_supabase.py       # Sincroniza√ß√£o cloud
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ logger.py              # Logging otimizado
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Script b√°sico
‚îÇ   ‚îú‚îÄ‚îÄ main_with_db.py        # Script completo
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ crontab                # Schedule de execu√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ entrypoint-cron.sh     # Entrypoint Docker
‚îÇ   ‚îú‚îÄ‚îÄ supabase_schema.sql    # Schema do Supabase
‚îÇ   ‚îî‚îÄ‚îÄ run_sync.py            # Helper de sincroniza√ß√£o
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o Docker
‚îú‚îÄ‚îÄ Dockerfile                  # Container da aplica√ß√£o
‚îú‚îÄ‚îÄ .env.example               # Configura√ß√µes de exemplo
‚îú‚îÄ‚îÄ DEPLOY.md                  # Guia de deploy
‚îú‚îÄ‚îÄ ARCHITECTURE.md            # Arquitetura detalhada
‚îî‚îÄ‚îÄ README.md                  # Este arquivo
```

## üöÄ Quick Start

### Desenvolvimento Local

```bash
# 1. Instalar depend√™ncias
cd scraper
pip install -r requirements.txt
playwright install chromium

# 2. Executar scraper b√°sico (SQLite)
python main_with_db.py
```

### Produ√ß√£o no Orange Pi

```bash
# 1. Setup inicial
git clone https://github.com/matheus-fsc/SteamBundleAPI.git
cd SteamBundleAPI
cp .env.example .env
nano .env  # Configure senhas

# 2. Build e start
docker compose up -d

# 3. Verificar
docker compose logs -f scraper-cron
```

## üê≥ Servi√ßos Docker

```bash
# Iniciar todos os servi√ßos
docker compose up -d

# Iniciar apenas scraper-cron (recomendado)
docker compose up -d postgres scraper-cron

# Ver logs
docker compose logs -f scraper-cron

# Executar manualmente
docker compose exec scraper python -m scraper.main_with_db

# Sincronizar Supabase
docker compose exec scraper python -m scraper.sync_supabase

# Parar tudo
docker compose down
```

## üìä Arquitetura

```
Steam ‚Üí Orange Pi (scraping + hist√≥rico) ‚Üí Supabase (vitrine)
         ‚Üì
    PostgreSQL Local (completo)
    - Hist√≥rico infinito
    - An√°lise de fraudes
    - Pre√ßos din√¢micos
         ‚Üì
    Supabase Cloud (otimizado)
    - API REST p√∫blica
    - √öltimos 30 dias
    - Apenas bundles v√°lidos
```

Ver [ARCHITECTURE.md](ARCHITECTURE.md) para detalhes completos.

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente (.env)

```bash
# Banco de dados local
DB_PASSWORD=senha_segura_aqui

# Scraper
REQUEST_DELAY=2
MAX_CONCURRENT_REQUESTS=5

# Supabase (opcional)
ENABLE_SUPABASE_SYNC=true
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_KEY=sua_key_aqui

# Timezone
TZ=America/Sao_Paulo
```

### Schedule de Execu√ß√µes

Edite `scripts/crontab`:

```cron
# Scraping √†s 3AM e 3PM
0 3 * * * cd /app && python -m scraper.main_with_db
0 15 * * * cd /app && python -m scraper.main_with_db

# Sync Supabase a cada 6 horas
0 */6 * * * cd /app && python -m scraper.sync_supabase
```

## üîç Detec√ß√£o de Promo√ß√µes Falsas

O sistema mant√©m hist√≥rico de pre√ßos e detecta automaticamente quando um "desconto" √© falso:

```python
# Exemplo de bundle com desconto falso
{
  "name": "Super Bundle",
  "discount": 75,
  "final_price": 50.0,
  "original_price": 200.0,  # ‚Üê Pre√ßo inflado!
  "is_discount_real": false,
  "discount_analysis": "Pre√ßo original inflado 144%"
}
```

**Como funciona:**
1. Coleta hist√≥rico dos √∫ltimos 30 dias
2. Calcula pre√ßo regular m√©dio (sem desconto)
3. Compara "original" atual com m√©dia hist√≥rica
4. Se > 150% da m√©dia ‚Üí marca como falso

## ‚òÅÔ∏è Supabase (Vitrine P√∫blica)

### Setup

1. Crie projeto no [Supabase](https://supabase.com)
2. Execute `scripts/supabase_schema.sql` no SQL Editor
3. Configure credenciais no `.env`
4. Reinicie containers

### Consumir API

```javascript
// JavaScript/TypeScript
import { createClient } from '@supabase/supabase-js'

const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)

// Top 10 deals
const { data } = await supabase
  .from('top_deals')
  .select('*')
  .limit(10)

// Filtrar por moeda
const { data } = await supabase
  .from('bundles')
  .select('*')
  .eq('currency', 'BRL')
  .gt('discount', 50)
  .order('discount', { ascending: false })
```

```python
# Python
from supabase import create_client

supabase = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

response = supabase.table('bundles')\
    .select('*')\
    .eq('currency', 'BRL')\
    .gt('discount', 50)\
    .execute()
```

```bash
# REST API direto
curl "https://seu-projeto.supabase.co/rest/v1/top_deals" \
  -H "apikey: SUPABASE_ANON_KEY"
```

## üõ°Ô∏è Prote√ß√£o do SD Card (Orange Pi)

O projeto est√° otimizado para evitar desgaste do cart√£o SD:

- ‚úÖ Logs apenas para stdout (Docker gerencia)
- ‚úÖ Banco em volume Docker (melhor I/O)
- ‚úÖ Tmpfs para arquivos tempor√°rios
- ‚úÖ Processo cron morre e renasce (evita memory leaks)

## üìà Monitoramento

```bash
# Health check
docker compose ps

# Logs em tempo real
docker compose logs -f scraper-cron

# Estat√≠sticas do banco
docker compose exec postgres psql -U steam -d steam_bundles -c \
  "SELECT COUNT(*), AVG(discount), AVG(final_price) FROM bundles WHERE is_valid = true;"

# Top deals no banco local
docker compose exec postgres psql -U steam -d steam_bundles -c \
  "SELECT name, discount, final_price FROM bundles 
   WHERE discount > 50 ORDER BY discount DESC LIMIT 10;"

# Uso de recursos
docker stats
```

## üîß Troubleshooting

### Playwright n√£o funciona

```bash
docker compose exec scraper playwright install chromium
```

### Banco n√£o conecta

```bash
# Verificar status
docker compose ps

# Ver logs
docker compose logs postgres

# Testar conex√£o
docker compose exec postgres psql -U steam -d steam_bundles
```

### Orange Pi lento

Reduza recursos no `.env`:

```bash
MAX_CONCURRENT_REQUESTS=2
REQUEST_DELAY=3
```

E no `docker-compose.yml`:

```yaml
deploy:
  resources:
    limits:
      cpus: '0.5'
      memory: 256M
```

### Supabase sync falha

```bash
# Testar conex√£o manualmente
docker compose exec scraper python -c "
from scraper.sync_supabase import SupabaseSync
sync = SupabaseSync()
print('OK' if sync.test_connection() else 'FALHOU')
"
```

## üìö Documenta√ß√£o

- [DEPLOY.md](DEPLOY.md) - Guia completo de deploy
- [ARCHITECTURE.md](ARCHITECTURE.md) - Arquitetura detalhada
- [scraper/README.md](scraper/README.md) - Documenta√ß√£o do m√≥dulo

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

MIT License - veja [LICENSE](LICENSE) para detalhes.

## üôè Cr√©ditos

- Scraping: BeautifulSoup + Playwright
- Banco: SQLAlchemy + PostgreSQL
- Cloud: Supabase
- Deploy: Docker + Orange Pi

## üîó Links √öteis

- [Steam Store](https://store.steampowered.com/bundles/)
- [Supabase Documentation](https://supabase.com/docs)
- [Playwright Python](https://playwright.dev/python/)
- [SQLAlchemy Async](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)
- [Orange Pi](https://www.armbian.com/orange-pi-5/)
