#!/usr/bin/env python3
"""
Script wrapper para execu√ß√£o do cron
Verifica se √© primeira execu√ß√£o e executa discovery automaticamente
"""
import asyncio
import os
import sys
import subprocess
from pathlib import Path
import fcntl
import time

# Adiciona path do projeto
sys.path.insert(0, '/app')

from scraper.database import Database
from scraper.logger import Logger
from sqlalchemy import select, func

# Flag para indicar que primeira execu√ß√£o j√° foi feita
FIRST_RUN_FLAG = Path('/app/data/.first_run_completed')
LOCK_FILE = Path('/app/data/.cron_lock')


async def check_and_run():
    """Verifica estado do banco e executa rotina apropriada"""
    logger = Logger('cron_wrapper')
    
    # Tenta adquirir lock para evitar execu√ß√µes concorrentes
    lock_fd = None
    try:
        lock_fd = open(LOCK_FILE, 'w')
        fcntl.flock(lock_fd.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    except IOError:
        # J√° existe outra inst√¢ncia rodando
        logger.info("‚è≠Ô∏è  Outra inst√¢ncia j√° est√° rodando, pulando...")
        return 0
    
    try:
        logger.info("ü§ñ Iniciando rotina autom√°tica do cron")
        
        # Verifica se banco est√° vazio
        logger.info(f"üîó DATABASE_URL: {os.getenv('DATABASE_URL', 'NOT SET')}")
        db = Database()
        logger.info("üîß Inicializando banco de dados...")
        await db.init_db()
        logger.success("‚úÖ Banco de dados inicializado!")
        
        from scraper.database import BundleModel
        async with db.async_session() as session:
            result = await session.execute(select(func.count(BundleModel.id)))
            total_bundles = result.scalar()
        
        is_first_run = (total_bundles == 0)
        
        if is_first_run:
            logger.info("üéØ PRIMEIRA EXECU√á√ÉO DETECTADA!")
            logger.info("üìã Executando discovery completo...")
            
            # Executa discovery E AGUARDA terminar
            discovery_result = subprocess.run(
                [sys.executable, '/app/scripts/discover_with_diff.py'],
                capture_output=True,
                text=True,
                timeout=1800  # 30 minutos de timeout
            )
            
            if discovery_result.returncode != 0:
                logger.error(f"‚ùå Erro no discovery: {discovery_result.stderr}")
                return 1
            
            logger.success("‚úÖ Discovery completo!")
            
            # Marca que primeira execu√ß√£o foi conclu√≠da
            FIRST_RUN_FLAG.touch()
            logger.info("‚úÖ Flag de primeira execu√ß√£o criada")
        else:
            logger.info(f"‚ÑπÔ∏è  Banco j√° possui {total_bundles} bundles")
        
        # Agora executa o scraping normal
        logger.info("üöÄ Iniciando scraping completo...")
        
        scraping_result = subprocess.run(
            [sys.executable, '-m', 'scraper.main_with_db'],
            cwd='/app',
            capture_output=False  # Output vai direto para stdout (logs do docker)
        )
        
        if scraping_result.returncode != 0:
            logger.error("‚ùå Erro no scraping")
            return 1
        
        logger.success("‚úÖ Rotina completa!")
        
        await db.close()
        return 0
        
    except Exception as e:
        import traceback
        logger.error(f"‚ùå Erro fatal: {e}")
        logger.error(f"Traceback completo:\n{traceback.format_exc()}")
        return 1
    finally:
        # Libera o lock
        if lock_fd:
            fcntl.flock(lock_fd.fileno(), fcntl.LOCK_UN)
            lock_fd.close()
            try:
                LOCK_FILE.unlink()
            except:
                pass


if __name__ == '__main__':
    exit_code = asyncio.run(check_and_run())
    sys.exit(exit_code)
