# Steam Bundle Scraper

Scraper modular em Python para extrair informa√ß√µes de bundles da Steam Store.

## Caracter√≠sticas

- **Scraping em duas fases**: 
  1. Varre p√°gina principal para listar todos os bundles
  2. Entra em cada bundle individualmente para extrair detalhes completos
  
- **Ass√≠ncrono**: Utiliza `asyncio` e `aiohttp` para scraping eficiente
- **Controle de rate-limit**: Delays configur√°veis entre requests
- **Retry autom√°tico**: Tenta novamente em caso de falhas tempor√°rias
- **Filtros avan√ßados**: Por desconto, pre√ßo, moeda, quantidade de jogos
- **Logging completo**: Rastreamento de todo o processo
- **Valida√ß√£o de dados**: Garante qualidade dos dados extra√≠dos

## Instala√ß√£o

```bash
# Instalar depend√™ncias
pip install -r requirements.txt
```

## Uso B√°sico

### Scraping Completo

```python
import asyncio
from scraper import BundleScraper
from filters import BundleFilter

async def main():
    async with BundleScraper() as scraper:
        # Scrape todos os bundles
        bundles = await scraper.scrape_all_bundles()
        
        # Aplica filtros
        filter_service = BundleFilter()
        bundles = filter_service.filter_valid(bundles)
        bundles = filter_service.filter_duplicates(bundles)
        
        print(f"Total: {len(bundles)} bundles")
        return bundles

asyncio.run(main())
```

### Scraping de Bundles Espec√≠ficos

```python
async with BundleScraper() as scraper:
    # IDs de bundles espec√≠ficos
    bundle_ids = ['28631', '469', '232']
    bundles = await scraper.scrape_all_bundles(bundle_ids)
```

### Teste com Bundle Individual

```python
async with BundleScraper() as scraper:
    bundle = await scraper.scrape_single_bundle('28631')
    print(bundle)
```

## Configura√ß√£o

Edite `config.py` para ajustar:

- **URLs e endpoints**
- **Delays entre requests** (importante para evitar bloqueio)
- **Timeouts e retries**
- **Seletores CSS** (caso a Steam mude a estrutura HTML)
- **Concorr√™ncia** (quantos requests simult√¢neos)

```python
from scraper import ScrapingConfig

# Ajustar configura√ß√µes
ScrapingConfig.REQUEST_DELAY = 3  # 3 segundos entre requests
ScrapingConfig.MAX_CONCURRENT_REQUESTS = 3  # 3 requests simult√¢neos
ScrapingConfig.TIMEOUT = 60  # Timeout de 60 segundos
```

## Filtros Dispon√≠veis

```python
from filters import BundleFilter

filter_service = BundleFilter()

# Filtros b√°sicos
bundles = filter_service.filter_valid(bundles)
bundles = filter_service.filter_duplicates(bundles)

# Por desconto
bundles = filter_service.filter_by_discount(bundles, min_discount=50)

# Por pre√ßo
bundles = filter_service.filter_by_price_range(bundles, min_price=10, max_price=100)

# Por quantidade de jogos
bundles = filter_service.filter_by_game_count(bundles, min_games=3)

# Por moeda
bundles = filter_service.filter_by_currency(bundles, 'BRL')

# Ordena√ß√£o
bundles = filter_service.sort_by_discount(bundles)
bundles = filter_service.sort_by_price(bundles)

# Estat√≠sticas
stats = filter_service.get_statistics(bundles)
print(stats)
```

## Estrutura de Dados

Cada bundle extra√≠do tem a seguinte estrutura:

```json
{
  "id": "28631",
  "name": "Valve Complete Pack",
  "price": {
    "final": 49.99,
    "original": 199.99,
    "currency": "BRL",
    "formatted": "R$ 49,99"
  },
  "discount": 75,
  "games": [
    {
      "name": "Counter-Strike: Global Offensive",
      "app_id": "730",
      "url": "https://store.steampowered.com/app/730/"
    }
  ],
  "url": "https://store.steampowered.com/bundle/28631/",
  "scraped_at": "2025-11-20T10:30:00.000Z",
  "is_valid": true
}
```

## Estrutura do Projeto

```
scraper/
‚îú‚îÄ‚îÄ __init__.py              # Exports principais
‚îú‚îÄ‚îÄ config.py                # Configura√ß√µes (URLs, delays, seletores)
‚îú‚îÄ‚îÄ scraper.py              # L√≥gica principal de scraping
‚îú‚îÄ‚îÄ mapper.py               # Transforma HTML ‚Üí objetos estruturados
‚îú‚îÄ‚îÄ filters.py              # Filtros e valida√ß√µes
‚îú‚îÄ‚îÄ logger.py               # Sistema de logging
‚îú‚îÄ‚îÄ main.py                 # Script de exemplo
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

## Arquitetura

A arquitetura replica a l√≥gica do scraper Node.js original:

### 1. **BundleScrapingService.js** ‚Üí **scraper.py**
- Navega√ß√£o pelas p√°ginas
- Controle de requests
- Orquestra√ß√£o do scraping

### 2. **BundleDataMapper.js** ‚Üí **mapper.py**
- Parsing de HTML
- Extra√ß√£o de dados estruturados
- Normaliza√ß√£o de pre√ßos e moedas

### 3. **BundleFilterService.js** ‚Üí **filters.py**
- Valida√ß√£o de dados
- Remo√ß√£o de duplicatas
- Filtros por crit√©rios diversos

### 4. **ScrapingConfigManager.js** ‚Üí **config.py**
- URLs e endpoints
- Seletores CSS
- Timeouts e delays

### 5. **PersistentLogger.js** ‚Üí **logger.py**
- Logging em arquivo e console
- Rastreamento de opera√ß√µes

## Performance

- **Ass√≠ncrono**: Processa m√∫ltiplos bundles simultaneamente
- **Batching**: Processa em lotes configur√°veis
- **Controle de concorr√™ncia**: Sem√°foro para limitar requests simult√¢neos
- **Rate limiting**: Delays autom√°ticos entre requests

## üê≥ Docker

Para rodar no Orange Pi:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY scraper/ ./scraper/

CMD ["python", "-m", "scraper.main"]
```

## Logs

Os logs s√£o salvos em:
- `logs/scraper_YYYYMMDD.log` - Log do dia
- Console - Output em tempo real

## Considera√ß√µes Importantes

1. **Rate Limiting**: A Steam pode bloquear IPs com muitos requests. Ajuste `REQUEST_DELAY`.
2. **User-Agent**: Headers est√£o configurados para parecer um browser real.
3. **Seletores CSS**: Podem mudar se a Steam atualizar o site. Monitore e ajuste em `config.py`.
4. **Regi√£o**: Pre√ßos e disponibilidade variam por regi√£o. Configure regi√£o no Steam.

