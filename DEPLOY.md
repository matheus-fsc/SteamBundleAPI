# Steam Bundle Scraper - Setup e Deploy no Orange Pi

## ðŸš€ Quick Start (Desenvolvimento Local)

```bash
# 1. Instalar dependÃªncias
cd scraper
pip install -r requirements.txt

# 2. Instalar browsers do Playwright
playwright install chromium

# 3. Executar scraper
python main_with_db.py
```

## ðŸ³ Deploy no Orange Pi com Docker

### PrÃ©-requisitos

```bash
# Instalar Docker e Docker Compose no Orange Pi
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# Instalar Docker Compose
sudo apt-get install docker-compose-plugin
```

### Setup

```bash
# 1. Clone o repositÃ³rio no Orange Pi
git clone https://github.com/matheus-fsc/SteamBundleAPI.git
cd SteamBundleAPI

# 2. Configure variÃ¡veis de ambiente
cp .env.example .env
nano .env  # Edite e adicione senha segura

# 3. Build e inicie containers
docker compose up -d

# 4. Verifique logs
docker compose logs -f scraper

# 5. Verifique banco de dados
docker compose exec postgres psql -U steam -d steam_bundles
```

### Comandos Ãšteis

```bash
# Ver logs
docker compose logs -f scraper

# Parar serviÃ§os
docker compose down

# Reiniciar scraper
docker compose restart scraper

# Executar scraper manualmente
docker compose exec scraper python -m scraper.main_with_db

# Backup do banco
docker compose exec postgres pg_dump -U steam steam_bundles > backup.sql

# Restore do banco
docker compose exec -T postgres psql -U steam steam_bundles < backup.sql

# Ver uso de recursos
docker stats

# Limpar dados antigos (cuidado!)
docker compose down -v  # Remove volumes tambÃ©m
```

## ðŸ“Š Estrutura de Banco de Dados

### Tabelas

- **bundles**: Bundles com histÃ³rico de preÃ§os
- **games**: Jogos individuais
- **scraping_logs**: Logs de execuÃ§Ãµes

### Queries Ãšteis

```sql
-- Top bundles por desconto
SELECT name, discount, final_price, currency 
FROM bundles 
WHERE discount > 50 
ORDER BY discount DESC 
LIMIT 10;

-- Bundles que precisam de browser scraping
SELECT id, name, needs_browser_scraping 
FROM bundles 
WHERE needs_browser_scraping = true;

-- HistÃ³rico de preÃ§os de um bundle
SELECT name, price_history 
FROM bundles 
WHERE id = '28631';

-- EstatÃ­sticas gerais
SELECT 
    COUNT(*) as total,
    AVG(discount) as avg_discount,
    AVG(final_price) as avg_price
FROM bundles 
WHERE is_valid = true;
```

## âš™ï¸ ConfiguraÃ§Ãµes

### ProteÃ§Ã£o do CartÃ£o SD

O projeto estÃ¡ configurado para proteger o cartÃ£o SD do Orange Pi:

1. **Logs em tmpfs**: Logs vÃ£o para RAM, nÃ£o para disco
2. **Volumes Docker**: Dados do PostgreSQL em volume gerenciado
3. **Read-only volumes**: CÃ³digo montado como read-only

### Ajuste de Performance

Para o Orange Pi, ajuste no `docker-compose.yml`:

```yaml
deploy:
  resources:
    limits:
      cpus: '1.0'      # Reduza se estiver lento
      memory: 512M     # Ajuste conforme RAM disponÃ­vel
```

### FrequÃªncia de Scraping

#### OpÃ§Ã£o 1: Cron no Docker (RECOMENDADO) âœ…

O projeto jÃ¡ vem com serviÃ§o `scraper-cron` configurado:

```bash
# Inicie o serviÃ§o de cron
docker compose up -d scraper-cron

# Verifique logs
docker compose logs -f scraper-cron

# Schedule padrÃ£o (scripts/crontab):
# - 3:00 AM: Scraping completo
# - 3:00 PM: Scraping rÃ¡pido
# - A cada 6h: Sync Supabase
```

**Vantagens do Cron no Docker:**
- âœ… Processo morre e renasce limpo (evita memory leaks)
- âœ… Isolado do sistema host
- âœ… Logs integrados com Docker
- âœ… FÃ¡cil de ajustar horÃ¡rios

**Customizar horÃ¡rios:**

Edite `scripts/crontab` e reinicie:

```bash
# Editar
nano scripts/crontab

# Reiniciar
docker compose restart scraper-cron
```

#### OpÃ§Ã£o 2: ExecuÃ§Ã£o Manual

```bash
# Scraping completo
docker compose exec scraper python -m scraper.main_with_db

# Apenas sincronizaÃ§Ã£o
docker compose exec scraper python -m scraper.sync_supabase
```

## ðŸ” EstratÃ©gia HÃ­brida de Scraping

O scraper usa duas fases:

### Fase 1: aiohttp (RÃ¡pido)
- Scraping bÃ¡sico de todos os bundles
- Detecta bundles com preÃ§os dinÃ¢micos
- ~90% dos bundles funcionam aqui

### Fase 2: Playwright (Pesado)
- Apenas para bundles que falharam na Fase 1
- Executa JavaScript para preÃ§os dinÃ¢micos
- Bundles "Complete Your Collection"

### DetecÃ§Ã£o AutomÃ¡tica

O scraper detecta automaticamente quando precisa de browser:
- PreÃ§o None ou 0
- Texto "Complete Your Collection"
- Elementos de preÃ§o dinÃ¢mico

## ðŸ“ˆ AnÃ¡lise de PromoÃ§Ãµes Reais

O sistema mantÃ©m histÃ³rico de preÃ§os para detectar "metade do dobro":

```python
# Analisar bundle especÃ­fico
from scraper.database import Database

async def analyze():
    db = Database()
    await db.init_db()
    
    bundle = await db.get_bundle_by_id('28631')
    analysis = bundle.get_real_discount()
    
    print(analysis)
    # {'is_real': False, 'reason': 'PreÃ§o original inflado', ...}

asyncio.run(analyze())
```

## ðŸ›¡ï¸ SeguranÃ§a

- Containers rodam como usuÃ¡rio nÃ£o-root
- Banco de dados com senha forte (configure em `.env`)
- Read-only volumes quando possÃ­vel
- Network isolada no Docker

## ðŸ“ Monitoramento

```bash
# Ver uso de recursos
docker stats

# Ver logs em tempo real
docker compose logs -f

# Ver Ãºltimas execuÃ§Ãµes
docker compose exec postgres psql -U steam -d steam_bundles -c "SELECT * FROM scraping_logs ORDER BY started_at DESC LIMIT 5;"
```

## ðŸ› Troubleshooting

### Playwright nÃ£o funciona

```bash
# Reinstalar browsers
docker compose exec scraper playwright install chromium
```

### Banco de dados nÃ£o conecta

```bash
# Verificar se PostgreSQL estÃ¡ rodando
docker compose ps

# Ver logs do banco
docker compose logs postgres

# Testar conexÃ£o
docker compose exec postgres psql -U steam -d steam_bundles
```

### Orange Pi fica lento

```bash
# Reduza concorrÃªncia no .env
MAX_CONCURRENT_REQUESTS=2
REQUEST_DELAY=3

# Reduza recursos no docker-compose.yml
cpus: '0.5'
memory: 256M
```

### CartÃ£o SD corrompendo

- Verifique se tmpfs estÃ¡ configurado para logs
- Use volume Docker para PostgreSQL (nÃ£o bind mount)
- Considere usar USB/SSD externo para dados

## â˜ï¸ SincronizaÃ§Ã£o com Supabase (Vitrine PÃºblica)

O Orange Pi Ã© a "fÃ¡brica" (scraping + banco local). O Supabase Ã© a "vitrine" (API pÃºblica).

### Setup do Supabase

1. **Crie projeto no Supabase** (gratuito): https://supabase.com

2. **Execute o schema SQL**:
   - VÃ¡ em SQL Editor no Supabase
   - Cole o conteÃºdo de `scripts/supabase_schema.sql`
   - Execute

3. **Configure credenciais**:

```bash
# Edite .env
nano .env

# Adicione:
ENABLE_SUPABASE_SYNC=true
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_KEY=sua_service_key_aqui
```

4. **Reinicie containers**:

```bash
docker compose down
docker compose up -d
```

### Como Funciona

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Scraping     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Sync      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Steam      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  Orange Pi   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   Supabase   â”‚
â”‚  (origem)   â”‚    (aiohttp)     â”‚  (Postgres)  â”‚  (upsert)   â”‚   (vitrine)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â†“                               â†“
                                  HistÃ³rico                     API PÃºblica
                                  Completo                      (Ãºltimos 30d)
```

### SincronizaÃ§Ã£o AutomÃ¡tica

O cron jÃ¡ executa sync a cada 6 horas. Para ajustar:

```bash
# Edite scripts/crontab
# Altere linha:
0 */6 * * * cd /app && python -m scraper.sync_supabase
```

### SincronizaÃ§Ã£o Manual

```bash
# Sync completo
docker compose exec scraper python -m scraper.sync_supabase

# Ou use o script helper
docker compose exec scraper python scripts/run_sync.py
```

### Limpeza de Dados Antigos

```python
# No script sync_supabase.py, chame:
await sync_to_supabase(cleanup_old=True)

# Remove bundles nÃ£o atualizados hÃ¡ 90+ dias
```

### Consultar API Supabase

```javascript
// No frontend (Next.js, React, etc)
import { createClient } from '@supabase/supabase-js'

const supabase = createClient(
  'https://seu-projeto.supabase.co',
  'sua_anon_key'  // Chave pÃºblica, nÃ£o a service_key!
)

// Top 10 deals
const { data } = await supabase
  .from('top_deals')
  .select('*')
  .limit(10)

// Bundles recentes
const { data } = await supabase
  .from('recent_bundles')
  .select('*')

// Filtrar por moeda
const { data } = await supabase
  .from('bundles')
  .select('*')
  .eq('currency', 'BRL')
  .eq('is_valid', true)
  .gt('discount', 50)
  .order('discount', { ascending: false })
```

## ðŸ“š ReferÃªncias

- [SQLAlchemy Async](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)
- [Playwright Python](https://playwright.dev/python/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [Orange Pi Optimization](https://www.armbian.com/orange-pi-5/)
- [Supabase Documentation](https://supabase.com/docs)
- [Supabase Python Client](https://supabase.com/docs/reference/python/introduction)
